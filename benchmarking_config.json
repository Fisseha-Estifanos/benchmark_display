[
    {
        "Name": "DATABRICKS benchmarking",
        "Metrics": ["Avg Correctness", "Avg Comprehensiveness", "Avg Readability"],
        "Values": [
            [0.85, 0.8, 1.0],
            [0.85, 0.85, 1.0],                            
            [0.95, 0.95, 1.0],
            [0.925, 0.925, 1.0],
            [0.95, 0.95, 1.0] 
        ]
    },
    {
        "Name": "RAGAS benchmarking",
        "Metrics": ["Context Precision", "Faithfulness",
                    "Answer relevancy", "context_recall"],
        "Values": [
            [0.9167, 0.8462, 0.7917, 0.8277],
            [0.9167, 0.8462, 0.8326, 0.9764],
            [0.7315, 0.7361, 0.7220, 0.7575],
            [0.8771, 0.9333, 0.8441, 0.9026],
            [0.9000, 0.8108, 0.8958, 0.7939]
        ]
    },
    {
        "name": "model names",
        "model_names" : ["RizzBuzz OpenAI", "RizzBuzz Claude3", "Chatbase", "RizzBuzz OpenAI improved", "RizzBuzz Claude3 improved"]
    },
    {
        "name": "colors",
        "colors": ["#fbd4cb", "#fac9b2", "#f8bd98", "#f6b27e", "#f6a66c", 
        "#f59a5c", "#f48d4d", "#f4854c", "#f48565", "#f4857f", "#f48599"]
    }
]